{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a288ad7-65d3-47d5-9fd1-c1c7f06e6e03",
   "metadata": {},
   "source": [
    "# LULC Classification with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34fd4b7f-ced4-42fd-bfb7-5a9af3b00ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS AND RANDOM SEEDS\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import reshape_as_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from patchify import unpatchify\n",
    "from patchify import patchify\n",
    "\n",
    "RNG_SEED = 42\n",
    "np.random.seed(RNG_SEED)\n",
    "tf.random.set_seed(RNG_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0dc5981-49da-4c36-b211-a1aaf790bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional - Used to play sound when slow cells are finished executing\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561b6db9-ecda-42d5-b8d2-4d9ea20abf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QoL Settings\n",
    "debug = 0\n",
    "optional_visuals = 0\n",
    "play_sounds = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "506c21f1-cf5d-4b5e-a357-2e24e1afc6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 128      # Size to split each training image into\n",
    "patch_step = 32       # Amount to step when splitting up images for training (<size means some overlap)\n",
    "\n",
    "percent_augment = 0.5 # Amount of the training data set to randomly augment (brightness, orientation)\n",
    "\n",
    "epochs = 150          # Epochs of training for the CNN (early stopping is enabled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4da8fa-ee33-48f9-bb5c-999965b0e0a1",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "924a17dc-2529-43ef-83d4-0d1fc4c1d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image_path = \"input/aerial_scaled.tif\"  # Aerial raster of entire area to be classified\n",
    "labels_aerial_path = \"input/aerial_512.tif\" # Aerial raster of just labelled data\n",
    "labels_classes_path = \"input/labels_raster_512.tif\" # Class raster of labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73e3bb3b-fa21-49f7-8bea-0eba62a094c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Image shape: (3, 1280, 1536)\n",
      "Labels Aerial shape: (3, 512, 512)\n",
      "Labels Classes shape: (512, 512)\n"
     ]
    }
   ],
   "source": [
    "# Load Full Image Aerial\n",
    "with rasterio.open(full_image_path) as src:\n",
    "    full_image_raw = src.read()  # Read all bands\n",
    "    full_image_meta = src.profile\n",
    "\n",
    "# Load Classes Raster of Labelled Sample\n",
    "with rasterio.open(labels_classes_path) as src:\n",
    "    labels_classes = src.read(1)  # Read the first (or only) band\n",
    "    labels_classes_meta = src.profile\n",
    "\n",
    "# Load Aerial Raster of Labelled Sample\n",
    "with rasterio.open(labels_aerial_path) as src:\n",
    "    labels_aerial_raw = src.read()\n",
    "    labels_aerial_meta = src.profile\n",
    "\n",
    "# Normalize images\n",
    "full_image = full_image_raw.astype(np.float32) / 255.0  # Normalize to 0-1 range\n",
    "labels_aerial = labels_aerial_raw.astype(np.float32) / 255.0 \n",
    "\n",
    "# Print shapes\n",
    "print(\"Full Image shape:\", full_image.shape)  # Should be (Bands, Height, Width)\n",
    "print(\"Labels Aerial shape:\", labels_aerial.shape)\n",
    "print(\"Labels Classes shape:\", labels_classes.shape)  # Should be (Height, Width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd91d4-faeb-4074-b2fe-95610a6861fc",
   "metadata": {},
   "source": [
    "#### ***Optional:*** *Visualize full aerial and labelled data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7fd393-9e70-4d72-aa3b-7b206cadb92b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if optional_visuals:\n",
    "    # Visualize full image\n",
    "    rasterio.plot.show(full_image)\n",
    "\n",
    "    # Visualize lablled aerial and classes\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[0].imshow(reshape_as_image(labels_aerial))\n",
    "    ax[1].imshow(labels_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb71ee6-ffb1-43d4-84d4-6f7811bdc27b",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381f17a5-b739-4e06-b915-9669838d35d0",
   "metadata": {},
   "source": [
    "### Split Label Image into Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93202bf8-f9dd-47ad-8663-fa81158a5802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 169 patches of size 128 x 128, with step 32\n"
     ]
    }
   ],
   "source": [
    "# Patchify\n",
    "patches_classes = patchify(labels_classes, (patch_size, patch_size), step=patch_step) # shape (num_patches, 3, patch_size, patch_size)\n",
    "patches_aerial = patchify(labels_aerial, (3, patch_size, patch_size), step=patch_step)[0] # shape (num_patches, patch_size, patch_size)\n",
    "\n",
    "# Reshape patches into one list\n",
    "X = patches_aerial.reshape(-1, 3, patch_size, patch_size) \n",
    "X = np.transpose(X, (0, 2, 3, 1)) \n",
    "\n",
    "Y = patches_classes.reshape(-1, patch_size, patch_size)\n",
    "\n",
    "num_patches = X.shape[0]\n",
    "\n",
    "if debug:\n",
    "    print(f\"(debug) - X (input) shape: {X.shape}\")\n",
    "    print(f\"(debug) - Y (labels) shape: {Y.shape}\")\n",
    "\n",
    "print(f\"Split into {num_patches} patches of size {patch_size} x {patch_size}, with step {patch_step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b63868-0a8b-443a-b595-21b4753be1d4",
   "metadata": {},
   "source": [
    "#### ***Optional:*** *Visualize patches*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bc93c56-77dc-450e-b370-576ef87aab13",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patches_to_show = 4 # How many patches to show (<20 recommended)\n",
    "\n",
    "if optional_visuals:    \n",
    "    shown = 0\n",
    "\n",
    "    # Visulaize aerial raster and class raster patches next to each other\n",
    "    while shown < min(patches_to_show, num_patches):    \n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10,10))\n",
    "    \n",
    "        ax[0].imshow(X[shown])\n",
    "        ax[1].imshow(Y[shown])\n",
    "\n",
    "        shown += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75359450-f39f-411d-a037-49cece993198",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "### Convert Class Labels to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0da0e15c-8e91-4419-a6e6-f9f1b6a2a54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y: Encoded 4 classes\n"
     ]
    }
   ],
   "source": [
    "# 0 building, 1 road, 2 vegetation, 3 alley/sidewalk/pavement\n",
    "num_classes = len(np.unique(Y))\n",
    "\n",
    "# Y classes are 1-indexed, need them 0-indexed\n",
    "Y_shifted = Y - 1\n",
    "\n",
    "# One hot encode the labels\n",
    "Y_one_hot = to_categorical(Y_shifted, num_classes=num_classes)\n",
    "\n",
    "print(f\"Y: Encoded {num_classes} classes\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62485392-2add-41e0-944f-0c25a93e91ba",
   "metadata": {},
   "source": [
    "### Split Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf8c8813-3c05-4b41-9bf8-68e1a5b6c5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set - X: (135, 128, 128, 3), Y: (135, 128, 128, 4)\n",
      "Test set -  X: (34, 128, 128, 3),  Y: (34, 128, 128, 4)\n"
     ]
    }
   ],
   "source": [
    "# Split data set into training and test sets\n",
    "X_train_orig, X_test, Y_train_orig, Y_test = train_test_split(X, Y_one_hot, test_size=0.2, random_state=RNG_SEED)\n",
    "print(f\"Train set - X: {X_train_orig.shape}, Y: {Y_train_orig.shape}\")\n",
    "print(f\"Test set -  X: {X_test.shape},  Y: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80ad63e-5080-4470-ba6e-e0a7d46c3097",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd7e3a76-d801-4acb-ab5a-3fd0c07e1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, label, brightness_factor=0.5, flip_prob=0.5):\n",
    "    # Random brightness\n",
    "    image = tf.image.random_brightness(image, max_delta=brightness_factor)\n",
    "\n",
    "    # Random horizontal flipping\n",
    "    if tf.random.uniform([]) < flip_prob:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbe95ddd-2e1a-4296-a41f-a9699f0816cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 67 augmented images. New training total: 202\n"
     ]
    }
   ],
   "source": [
    "# Randomly select indices for augmentation\n",
    "num_aug_samples = int(percent_augment * X_train_orig.shape[0])\n",
    "augment_indices = np.random.choice(X_train_orig.shape[0], num_aug_samples, replace=False)\n",
    "\n",
    "# Apply augmentation\n",
    "X_aug = []\n",
    "Y_aug = []\n",
    "for idx in augment_indices:\n",
    "    new_image, new_label = augment(X_train_orig[idx], Y_train_orig[idx])\n",
    "    X_aug.append(np.array(new_image))  # Convert Tensor to NumPy\n",
    "    Y_aug.append(np.array(new_label))\n",
    "\n",
    "# Convert to NumPy and concatenate with original dataset\n",
    "X_aug = np.array(X_aug)\n",
    "Y_aug = np.array(Y_aug)\n",
    "\n",
    "X_train = np.concatenate([X_train_orig, X_aug], axis=0)\n",
    "Y_train = np.concatenate([Y_train_orig, Y_aug], axis=0)\n",
    "\n",
    "print(f\"Added {num_aug_samples} augmented images. New training total: {X_train.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea448ee-b2e1-4f01-af63-982256c2fe4a",
   "metadata": {},
   "source": [
    "## Build CNN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6846233-ea19-4fce-8820-b6f841045193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ up_sampling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ up_sampling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ up_sampling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ up_sampling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m590,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ up_sampling2d_4 (\u001b[38;5;33mUpSampling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m295,040\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ up_sampling2d_5 (\u001b[38;5;33mUpSampling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m73,792\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ up_sampling2d_6 (\u001b[38;5;33mUpSampling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │          \u001b[38;5;34m18,464\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ up_sampling2d_7 (\u001b[38;5;33mUpSampling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │             \u001b[38;5;34m132\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,365,924</span> (5.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,365,924\u001b[0m (5.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,365,924</span> (5.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,365,924\u001b[0m (5.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(128,128,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(256, (3,3), activation='relu', padding='same'),\n",
    "    layers.UpSampling2D((2,2)),  # Upsample back\n",
    "\n",
    "    layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    layers.UpSampling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    layers.UpSampling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "    layers.UpSampling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(4, (1,1), activation='softmax')  # Output 4 classes per pixel\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e4ce9-27a4-4bae-968e-ccc8c6c0eb6c",
   "metadata": {},
   "source": [
    "### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151de709-3382-45a8-a977-e3b0790844fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - accuracy: 0.4861 - loss: 1.2297 - val_accuracy: 0.5164 - val_loss: 1.1278\n",
      "Epoch 2/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.5252 - loss: 1.1245 - val_accuracy: 0.5147 - val_loss: 1.1040\n",
      "Epoch 3/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.5253 - loss: 1.1045 - val_accuracy: 0.5164 - val_loss: 1.0929\n",
      "Epoch 4/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.5253 - loss: 1.1239 - val_accuracy: 0.5164 - val_loss: 1.0841\n",
      "Epoch 5/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.5253 - loss: 1.0829 - val_accuracy: 0.5164 - val_loss: 1.0650\n",
      "Epoch 6/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.5253 - loss: 1.0721 - val_accuracy: 0.5164 - val_loss: 1.0032\n",
      "Epoch 7/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.5262 - loss: 1.0237 - val_accuracy: 0.4865 - val_loss: 1.0715\n",
      "Epoch 8/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.4945 - loss: 1.0631 - val_accuracy: 0.6214 - val_loss: 0.8871\n",
      "Epoch 9/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.6095 - loss: 0.9319 - val_accuracy: 0.7027 - val_loss: 0.7211\n",
      "Epoch 10/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.6607 - loss: 0.8106 - val_accuracy: 0.7561 - val_loss: 0.6109\n",
      "Epoch 11/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.7175 - loss: 0.7061 - val_accuracy: 0.6865 - val_loss: 0.8021\n",
      "Epoch 12/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.7142 - loss: 0.7132 - val_accuracy: 0.7890 - val_loss: 0.5383\n",
      "Epoch 13/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.7432 - loss: 0.6567 - val_accuracy: 0.8002 - val_loss: 0.5083\n",
      "Epoch 14/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.7787 - loss: 0.5638 - val_accuracy: 0.8281 - val_loss: 0.4515\n",
      "Epoch 15/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.8025 - loss: 0.5121 - val_accuracy: 0.8519 - val_loss: 0.3706\n",
      "Epoch 16/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.8278 - loss: 0.4406 - val_accuracy: 0.8590 - val_loss: 0.3499\n",
      "Epoch 17/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.8353 - loss: 0.4067 - val_accuracy: 0.8620 - val_loss: 0.3346\n",
      "Epoch 18/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.8461 - loss: 0.3789 - val_accuracy: 0.8748 - val_loss: 0.3071\n",
      "Epoch 19/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.8542 - loss: 0.3664 - val_accuracy: 0.8843 - val_loss: 0.2961\n",
      "Epoch 20/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.8737 - loss: 0.3164 - val_accuracy: 0.9026 - val_loss: 0.2412\n",
      "Epoch 21/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.8905 - loss: 0.2720 - val_accuracy: 0.8977 - val_loss: 0.2671\n",
      "Epoch 22/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.8942 - loss: 0.2651 - val_accuracy: 0.9072 - val_loss: 0.2258\n",
      "Epoch 23/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.9059 - loss: 0.2340 - val_accuracy: 0.9139 - val_loss: 0.2112\n",
      "Epoch 24/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.9092 - loss: 0.2249 - val_accuracy: 0.9193 - val_loss: 0.1969\n",
      "Epoch 25/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.9135 - loss: 0.2116 - val_accuracy: 0.9042 - val_loss: 0.2358\n",
      "Epoch 26/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.9107 - loss: 0.2196 - val_accuracy: 0.9025 - val_loss: 0.2367\n",
      "Epoch 27/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.9116 - loss: 0.2128 - val_accuracy: 0.9310 - val_loss: 0.1676\n",
      "Epoch 28/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.9194 - loss: 0.1922 - val_accuracy: 0.9239 - val_loss: 0.1899\n",
      "Epoch 29/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 0.9291 - loss: 0.1714 - val_accuracy: 0.9363 - val_loss: 0.1567\n",
      "Epoch 30/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.9395 - loss: 0.1450 - val_accuracy: 0.9393 - val_loss: 0.1520\n",
      "Epoch 31/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.9451 - loss: 0.1308 - val_accuracy: 0.9396 - val_loss: 0.1533\n",
      "Epoch 32/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step - accuracy: 0.9459 - loss: 0.1285 - val_accuracy: 0.9404 - val_loss: 0.1484\n",
      "Epoch 33/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.9460 - loss: 0.1297 - val_accuracy: 0.9459 - val_loss: 0.1339\n",
      "Epoch 34/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.9447 - loss: 0.1321 - val_accuracy: 0.9438 - val_loss: 0.1398\n",
      "Epoch 35/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.9423 - loss: 0.1403 - val_accuracy: 0.9331 - val_loss: 0.1639\n",
      "Epoch 36/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.9447 - loss: 0.1311 - val_accuracy: 0.9454 - val_loss: 0.1361\n",
      "Epoch 37/150\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.9514 - loss: 0.1150 - val_accuracy: 0.9354 - val_loss: 0.1589\n",
      "Epoch 38/150\n",
      "\u001b[1m18/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.9498 - loss: 0.1198 "
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    epochs=epochs, batch_size=10, \n",
    "                    callbacks=[early_stopping],\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237e7bf6-de36-42e5-951e-9b4cb49efb6b",
   "metadata": {},
   "source": [
    "### Evaluate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0104cb7-d43e-45c2-96b1-30590f4451f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss & accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Beep when done, if enabled\n",
    "if play_sounds:\n",
    "    beep = np.sin(2*np.pi*800*np.arange(3000*2)/10000)\n",
    "    Audio(beep, rate=6000, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54258c16-0177-433e-8874-94bbda3f7ed2",
   "metadata": {},
   "source": [
    "## Predict the Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad0b27-18a5-4969-945b-b2b0beb1b4f3",
   "metadata": {},
   "source": [
    "### Full Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bbc6a2-c199-40ab-8c72-87052ab83f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_full_step = patch_step\n",
    "\n",
    "full_image_reshaped = reshape_as_image(full_image)\n",
    "print(\"Full Image shape:\", full_image_reshaped.shape)  # (2347, 2560, 3)\n",
    "\n",
    "patches_full = patchify(full_image_reshaped, (patch_size, patch_size, 3), step=patch_full_step)\n",
    "#patches_full = patches_full[0]\n",
    "patches_full_x, patches_full_y = patches_full.shape[0:2]\n",
    "print(patches_full_x, patches_full_y)\n",
    "print(\"Patched Image shape:\", patches_full.shape)  \n",
    "\n",
    "patches_full_reshaped = patches_full.reshape(-1, patch_size, patch_size, 3)\n",
    "print(\"Reshaped for Model shape:\", patches_full_reshaped.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193e7f26-7f05-4c6b-968f-badc67ab6f0e",
   "metadata": {},
   "source": [
    "### Full Image Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9785f607-28d1-4609-81d4-e02a838eb9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(patches_full_reshaped)\n",
    "print(\"Predictions shape:\", predictions.shape) \n",
    "\n",
    "predictions = predictions.reshape(patches_full.shape[0], patches_full.shape[1], patch_size, patch_size, -1)\n",
    "print(\"Reshaped Predictions shape:\", predictions.shape)\n",
    "\n",
    "predicted_classes = np.argmax(predictions, axis=-1)\n",
    "print(\"Predicted Classes shape:\", predicted_classes.shape)\n",
    "\n",
    "## BLENDING MATRIX IMPLEMENTATION\n",
    "# Initialize accumulation and weight matrices\n",
    "full_prediction = np.zeros((patches_full_x * patch_full_step + patch_size, \n",
    "                            patches_full_y * patch_full_step + patch_size), dtype=np.float32)\n",
    "weight_matrix = np.zeros_like(full_prediction, dtype=np.float32)\n",
    "\n",
    "# Blend patches\n",
    "for i in range(patches_full_x):\n",
    "    for j in range(patches_full_y):\n",
    "        x_start = i * patch_full_step\n",
    "        x_end = x_start + patch_size\n",
    "        y_start = j * patch_full_step\n",
    "        y_end = y_start + patch_size\n",
    "        \n",
    "        full_prediction[x_start:x_end, y_start:y_end] += predicted_classes[i, j]\n",
    "        weight_matrix[x_start:x_end, y_start:y_end] += 1  # Track contributions\n",
    "\n",
    "# Normalize by the number of times each pixel was predicted\n",
    "full_prediction /= weight_matrix\n",
    "full_prediction = full_prediction.astype(np.uint8)\n",
    "print(\"Blended Full Prediction shape:\", full_prediction.shape)\n",
    "\n",
    "rasterio.plot.show(full_image)\n",
    "rasterio.plot.show(full_prediction)\n",
    "\n",
    "# ---------------------------[ \n",
    "# Beep when done, if enabled\n",
    "if play_sounds:\n",
    "    beep = np.sin(2*np.pi*800*np.arange(3000*2)/10000)\n",
    "    Audio(beep, rate=6000, autoplay=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
